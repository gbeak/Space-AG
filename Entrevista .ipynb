{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "\n",
    "import time\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "from geojson import Polygon\n",
    "from sentinelhub import WmsRequest, WcsRequest, MimeType, CRS, BBox\n",
    "\n",
    "from sentinelhub import SentinelHubRequest, SentinelHubDownloadClient, DataSource, \\\n",
    "    MimeType, DownloadRequest, CRS, BBox\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "import re\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract date from SentinelHubImage-available_dates.xlsx\t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         _date\n",
      "0   2020-04-20\n",
      "1   2020-04-15\n",
      "2   2020-03-11\n",
      "3   2020-02-15\n",
      "4   2020-02-10\n",
      "..         ...\n",
      "84  2016-12-22\n",
      "85  2016-12-02\n",
      "86  2016-11-22\n",
      "87  2016-09-13\n",
      "88  2016-07-15\n",
      "\n",
      "[89 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_excel('https://bitbucket.org/adoval4/space-ag-data-analyst-challenge/raw/37385be5a0c78d3b98b64ccc99e6172d36ad68ea/SentinelHubImage-available_dates.xlsx', index=False)\n",
    "#print(df3)\n",
    "date = df3[['_date']]\n",
    "\n",
    "\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Geometry from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         minx       miny       maxx       maxy\n",
      "0  -75.642984 -14.200629 -75.639658 -14.197876\n",
      "1  -75.645651 -14.201559 -75.642317 -14.198803\n",
      "2  -75.642317 -14.202454 -75.638989 -14.199701\n",
      "3  -75.644984 -14.203384 -75.641650 -14.200629\n",
      "4  -75.641650 -14.204280 -75.638321 -14.201527\n",
      "5  -75.644319 -14.205212 -75.640982 -14.202454\n",
      "6  -75.640982 -14.206095 -75.637657 -14.203352\n",
      "7  -75.643652 -14.207029 -75.640319 -14.204280\n",
      "8  -75.640319 -14.207924 -75.636986 -14.205165\n",
      "9  -75.642990 -14.208854 -75.639650 -14.206095\n",
      "10 -75.639650 -14.209740 -75.636322 -14.206998\n",
      "11 -75.642324 -14.210673 -75.638987 -14.207924\n",
      "12 -75.638987 -14.211560 -75.635656 -14.208810\n",
      "13 -75.641661 -14.212492 -75.638321 -14.209740\n",
      "14 -75.638321 -14.213385 -75.634988 -14.210631\n",
      "15 -75.640998 -14.214319 -75.637654 -14.211560\n",
      "16 -75.637654 -14.215142 -75.634345 -14.212454\n",
      "17 -75.640332 -14.216077 -75.637012 -14.213385\n",
      "18 -75.647639 -14.196068 -75.644346 -14.193356\n",
      "19 -75.652318 -14.199735 -75.649033 -14.197043\n",
      "20 -75.643642 -14.198732 -75.640349 -14.196025\n",
      "21 -75.646324 -14.199663 -75.643037 -14.196959\n",
      "22 -75.651667 -14.201514 -75.648381 -14.198829\n",
      "23 -75.645612 -14.193291 -75.642341 -14.190610\n",
      "24 -75.650976 -14.195155 -75.647697 -14.192480\n",
      "25 -75.653648 -14.196086 -75.650378 -14.193419\n",
      "26 -75.644955 -14.195133 -75.641667 -14.192430\n",
      "27 -75.650314 -14.197027 -75.647010 -14.194283\n",
      "28 -75.652986 -14.197960 -75.649690 -14.195220\n",
      "29 -75.644302 -14.196943 -75.641004 -14.194213\n",
      "30 -75.646983 -14.197881 -75.643688 -14.195148\n",
      "31 -75.649644 -14.198814 -75.646355 -14.196108\n",
      "32 -75.648988 -14.200586 -75.645703 -14.197890\n"
     ]
    }
   ],
   "source": [
    "json_data = 'https://bitbucket.org/adoval4/space-ag-data-analyst-challenge/raw/37385be5a0c78d3b98b64ccc99e6172d36ad68ea/farm_map.json'\n",
    "\n",
    "df1 = gpd.read_file(json_data)\n",
    "df1 = df1[['geometry']]\n",
    "polygon = df1\n",
    "df1 = df1.bounds\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract property values and area from features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NVDI is calculated \n",
    "$ \\frac{NIR - RED}{NIR + RED} $\n",
    "\n",
    "NIR - reflection in the near-infrared spectrum\n",
    "RED - reflection in the red range of the spectrum\n",
    "\n",
    "I was looking into farm_map.json, but there was no such value that can be NVDI (between -1 and 1).\n",
    "Thus, I decided to use Crop Yield (Ha/t). Following code shows crop yield, and all values from 2019-09-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        values      unit  crop yield\n",
      "0  3581.158766  6.530601    0.548366\n",
      "1  4037.375179  6.555069    0.615916\n",
      "2  4658.420440  6.533254    0.713032\n",
      "3  4196.272166  6.551013    0.640553\n",
      "4  4744.580970  6.534646    0.726066\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "df2 = gpd.read_file(json_data)\n",
    "df2 = df2[['values', 'unit']]\n",
    "df2 = df2.astype(str)\n",
    "df2['values'] = df2['values'].apply(lambda x: x.replace('[','').replace(']','').replace('{', '').replace('}', ''))\n",
    "df2['unit'] = df2['unit'].apply(lambda x: x.replace('[','').replace(']','').replace('{', '').replace('}', ''))\n",
    "\n",
    "df2['values'] = df2['values'].apply(lambda x: x.replace(x, x.split(',')[0]))\n",
    "df2['unit'] = df2['unit'].apply(lambda x: x.replace(x, x.split(',')[0]))\n",
    "\n",
    "df2['values'] = df2['values'].apply(lambda x: re.sub(r'[a-z]+', '', x, re.I))\n",
    "df2['values'] = df2['values'].apply(lambda x: x.replace('  \"\": ', ''))\n",
    "\n",
    "df2['unit'] = df2['unit'].apply(lambda x: re.sub(r'[a-z]+', '', x, re.I))\n",
    "df2['unit'] = df2['unit'].apply(lambda x: x.replace(\"state': 'area': \", ''))\n",
    "df2['unit'] = df2['unit'].apply(lambda x: x.replace(\"'': '':\", ''))\n",
    "\n",
    "df2 = df2.astype(float)\n",
    "df2['crop yield'] = df2['values'] / 1000 / df2['unit']\n",
    " \n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image, factor=1):\n",
    "    \"\"\"\n",
    "    Utility function for plotting RGB images.\n",
    "    \"\"\"\n",
    "    fig = plt.subplots(nrows=1, ncols=1, figsize=(15, 7))\n",
    "\n",
    "    if np.issubdtype(image.dtype, np.floating):\n",
    "        plt.imshow(np.minimum(image * factor, 1))\n",
    "    else:\n",
    "        plt.imshow(image) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the NDVI images of each batch and each date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assign directory value as a global\n",
    "2. Loop to save image with each polygon location and each date\n",
    "3. Get the list of file name from the directory\n",
    "4. Create a DataFrame including date, polygon location, and file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiate  1 th row\n",
      "initiate  1 th date\n",
      "save image from 1 th row and  1 th date\n",
      "initiate  2 th date\n",
      "save image from 1 th row and  2 th date\n",
      "initiate  3 th date\n",
      "save image from 1 th row and  3 th date\n",
      "initiate  4 th date\n",
      "save image from 1 th row and  4 th date\n",
      "initiate  5 th date\n",
      "save image from 1 th row and  5 th date\n",
      "initiate  6 th date\n",
      "save image from 1 th row and  6 th date\n",
      "initiate  7 th date\n",
      "save image from 1 th row and  7 th date\n",
      "initiate  8 th date\n",
      "save image from 1 th row and  8 th date\n",
      "initiate  9 th date\n",
      "save image from 1 th row and  9 th date\n",
      "initiate  10 th date\n",
      "save image from 1 th row and  10 th date\n",
      "initiate  11 th date\n",
      "save image from 1 th row and  11 th date\n",
      "initiate  12 th date\n",
      "save image from 1 th row and  12 th date\n",
      "initiate  13 th date\n",
      "save image from 1 th row and  13 th date\n",
      "initiate  14 th date\n",
      "save image from 1 th row and  14 th date\n",
      "initiate  15 th date\n",
      "save image from 1 th row and  15 th date\n",
      "initiate  16 th date\n",
      "save image from 1 th row and  16 th date\n",
      "initiate  17 th date\n",
      "save image from 1 th row and  17 th date\n",
      "initiate  18 th date\n",
      "save image from 1 th row and  18 th date\n",
      "initiate  19 th date\n",
      "save image from 1 th row and  19 th date\n",
      "initiate  20 th date\n",
      "save image from 1 th row and  20 th date\n",
      "initiate  21 th date\n",
      "save image from 1 th row and  21 th date\n",
      "initiate  22 th date\n",
      "save image from 1 th row and  22 th date\n",
      "initiate  23 th date\n",
      "save image from 1 th row and  23 th date\n",
      "initiate  24 th date\n",
      "save image from 1 th row and  24 th date\n",
      "initiate  25 th date\n",
      "save image from 1 th row and  25 th date\n",
      "initiate  26 th date\n",
      "save image from 1 th row and  26 th date\n",
      "initiate  27 th date\n",
      "save image from 1 th row and  27 th date\n",
      "initiate  28 th date\n",
      "save image from 1 th row and  28 th date\n",
      "initiate  29 th date\n",
      "save image from 1 th row and  29 th date\n",
      "initiate  30 th date\n",
      "save image from 1 th row and  30 th date\n",
      "initiate  31 th date\n",
      "save image from 1 th row and  31 th date\n",
      "initiate  32 th date\n",
      "save image from 1 th row and  32 th date\n",
      "initiate  33 th date\n",
      "save image from 1 th row and  33 th date\n",
      "initiate  34 th date\n",
      "save image from 1 th row and  34 th date\n",
      "initiate  35 th date\n",
      "save image from 1 th row and  35 th date\n",
      "initiate  36 th date\n",
      "save image from 1 th row and  36 th date\n",
      "initiate  37 th date\n",
      "save image from 1 th row and  37 th date\n",
      "initiate  38 th date\n",
      "save image from 1 th row and  38 th date\n",
      "initiate  39 th date\n",
      "save image from 1 th row and  39 th date\n",
      "initiate  40 th date\n",
      "save image from 1 th row and  40 th date\n",
      "initiate  41 th date\n",
      "save image from 1 th row and  41 th date\n",
      "initiate  42 th date\n",
      "save image from 1 th row and  42 th date\n",
      "initiate  43 th date\n",
      "save image from 1 th row and  43 th date\n",
      "initiate  44 th date\n",
      "save image from 1 th row and  44 th date\n",
      "initiate  45 th date\n",
      "save image from 1 th row and  45 th date\n",
      "initiate  46 th date\n",
      "save image from 1 th row and  46 th date\n",
      "initiate  47 th date\n",
      "save image from 1 th row and  47 th date\n",
      "initiate  48 th date\n",
      "save image from 1 th row and  48 th date\n",
      "initiate  49 th date\n",
      "save image from 1 th row and  49 th date\n",
      "initiate  50 th date\n",
      "save image from 1 th row and  50 th date\n",
      "initiate  51 th date\n",
      "save image from 1 th row and  51 th date\n",
      "initiate  52 th date\n",
      "save image from 1 th row and  52 th date\n",
      "initiate  53 th date\n",
      "save image from 1 th row and  53 th date\n",
      "initiate  54 th date\n",
      "save image from 1 th row and  54 th date\n",
      "initiate  55 th date\n",
      "save image from 1 th row and  55 th date\n",
      "initiate  56 th date\n",
      "save image from 1 th row and  56 th date\n",
      "initiate  57 th date\n",
      "save image from 1 th row and  57 th date\n",
      "initiate  58 th date\n",
      "save image from 1 th row and  58 th date\n",
      "initiate  59 th date\n",
      "save image from 1 th row and  59 th date\n",
      "initiate  60 th date\n",
      "save image from 1 th row and  60 th date\n",
      "initiate  61 th date\n",
      "save image from 1 th row and  61 th date\n",
      "initiate  62 th date\n",
      "save image from 1 th row and  62 th date\n",
      "initiate  63 th date\n",
      "save image from 1 th row and  63 th date\n",
      "initiate  64 th date\n",
      "save image from 1 th row and  64 th date\n",
      "initiate  65 th date\n",
      "save image from 1 th row and  65 th date\n",
      "initiate  66 th date\n",
      "save image from 1 th row and  66 th date\n",
      "initiate  67 th date\n",
      "save image from 1 th row and  67 th date\n",
      "initiate  68 th date\n",
      "save image from 1 th row and  68 th date\n",
      "initiate  69 th date\n",
      "save image from 1 th row and  69 th date\n",
      "initiate  70 th date\n",
      "save image from 1 th row and  70 th date\n",
      "initiate  71 th date\n",
      "save image from 1 th row and  71 th date\n",
      "initiate  72 th date\n",
      "save image from 1 th row and  72 th date\n",
      "initiate  73 th date\n",
      "save image from 1 th row and  73 th date\n",
      "initiate  74 th date\n",
      "save image from 1 th row and  74 th date\n",
      "initiate  75 th date\n",
      "save image from 1 th row and  75 th date\n",
      "initiate  76 th date\n",
      "save image from 1 th row and  76 th date\n",
      "initiate  77 th date\n",
      "save image from 1 th row and  77 th date\n",
      "initiate  78 th date\n",
      "save image from 1 th row and  78 th date\n",
      "initiate  79 th date\n",
      "save image from 1 th row and  79 th date\n",
      "initiate  80 th date\n",
      "save image from 1 th row and  80 th date\n",
      "initiate  81 th date\n",
      "save image from 1 th row and  81 th date\n",
      "initiate  82 th date\n",
      "save image from 1 th row and  82 th date\n",
      "initiate  83 th date\n",
      "save image from 1 th row and  83 th date\n",
      "initiate  84 th date\n",
      "save image from 1 th row and  84 th date\n",
      "initiate  85 th date\n",
      "save image from 1 th row and  85 th date\n",
      "initiate  86 th date\n",
      "save image from 1 th row and  86 th date\n",
      "initiate  87 th date\n",
      "save image from 1 th row and  87 th date\n",
      "initiate  88 th date\n",
      "save image from 1 th row and  88 th date\n",
      "initiate  89 th date\n",
      "save image from 1 th row and  89 th date\n",
      "initiate  2 th row\n",
      "initiate  1 th date\n",
      "save image from 2 th row and  1 th date\n",
      "initiate  2 th date\n",
      "save image from 2 th row and  2 th date\n",
      "initiate  3 th date\n",
      "save image from 2 th row and  3 th date\n",
      "initiate  4 th date\n",
      "save image from 2 th row and  4 th date\n",
      "initiate  5 th date\n",
      "save image from 2 th row and  5 th date\n",
      "initiate  6 th date\n",
      "save image from 2 th row and  6 th date\n",
      "initiate  7 th date\n",
      "save image from 2 th row and  7 th date\n",
      "initiate  8 th date\n",
      "save image from 2 th row and  8 th date\n",
      "initiate  9 th date\n",
      "save image from 2 th row and  9 th date\n",
      "initiate  10 th date\n",
      "save image from 2 th row and  10 th date\n",
      "initiate  11 th date\n",
      "save image from 2 th row and  11 th date\n",
      "initiate  12 th date\n",
      "save image from 2 th row and  12 th date\n",
      "initiate  13 th date\n",
      "save image from 2 th row and  13 th date\n",
      "initiate  14 th date\n",
      "save image from 2 th row and  14 th date\n",
      "initiate  15 th date\n",
      "save image from 2 th row and  15 th date\n",
      "initiate  16 th date\n",
      "save image from 2 th row and  16 th date\n",
      "initiate  17 th date\n",
      "save image from 2 th row and  17 th date\n",
      "initiate  18 th date\n",
      "save image from 2 th row and  18 th date\n",
      "initiate  19 th date\n",
      "save image from 2 th row and  19 th date\n",
      "initiate  20 th date\n",
      "save image from 2 th row and  20 th date\n",
      "initiate  21 th date\n",
      "save image from 2 th row and  21 th date\n",
      "initiate  22 th date\n",
      "save image from 2 th row and  22 th date\n",
      "initiate  23 th date\n",
      "save image from 2 th row and  23 th date\n",
      "initiate  24 th date\n",
      "save image from 2 th row and  24 th date\n",
      "initiate  25 th date\n",
      "save image from 2 th row and  25 th date\n",
      "initiate  26 th date\n",
      "save image from 2 th row and  26 th date\n",
      "initiate  27 th date\n",
      "save image from 2 th row and  27 th date\n",
      "initiate  28 th date\n",
      "save image from 2 th row and  28 th date\n",
      "initiate  29 th date\n",
      "save image from 2 th row and  29 th date\n",
      "initiate  30 th date\n",
      "save image from 2 th row and  30 th date\n",
      "initiate  31 th date\n",
      "save image from 2 th row and  31 th date\n",
      "initiate  32 th date\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-21b0e2657d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         wms_true_color_request = WmsRequest(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global directory \n",
    "\n",
    "directory = '/Users/gbeak/Desktop/Study Materials/img'\n",
    "\n",
    "for i in range(0, len(df1)):\n",
    "    print('initiate ', i + 1, 'th row')\n",
    "    bestiboka_coords_wgs84 = df1.iloc[i].values.tolist()\n",
    "    bestiboka_bbox = BBox(bbox=bestiboka_coords_wgs84, crs=CRS.WGS84)\n",
    "    time.sleep(1)\n",
    "    for j in range(0, len(df3)):\n",
    "        print('initiate ', j + 1, 'th date')\n",
    "        for folder, _, filenames in os.walk(directory):\n",
    "            for filename in filenames:\n",
    "                os.path.join(folder, filename)\n",
    "                time.sleep(1)\n",
    "        date = df3['_date'].iloc[j]\n",
    "        wms_true_color_request = WmsRequest(\n",
    "            data_folder = directory,\n",
    "            layer='TRUE-COLOR-S2-L1C',\n",
    "            bbox=betsiboka_bbox,\n",
    "            time=date,\n",
    "            width=512,\n",
    "            height=856)\n",
    "        time.sleep(1)\n",
    "        wms_true_color_img = wms_true_color_request.get_data(save_data=True)\n",
    "        print('save image from', i + 1, 'th row and ', j + 1, 'th date')\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date                                            Polygon\n",
      "0   2020-04-20  POLYGON ((-75.6396578867764 -14.19970133595172...\n",
      "1   2020-04-20  POLYGON ((-75.64231663022875 -14.2006288241436...\n",
      "2   2020-04-20  POLYGON ((-75.63898926117189 -14.2015272683264...\n",
      "3   2020-04-20  POLYGON ((-75.64164955317383 -14.2024540244683...\n",
      "4   2020-04-20  POLYGON ((-75.64164955317383 -14.2024540244683...\n",
      "..         ...                                                ...\n",
      "28  2016-07-15  POLYGON ((-75.64968970670726 -14.1970429501923...\n",
      "29  2016-07-15  POLYGON ((-75.64430202199843 -14.1951328024683...\n",
      "30  2016-07-15  POLYGON ((-75.64698264826821 -14.1960684956183...\n",
      "31  2016-07-15  POLYGON ((-75.64964409685477 -14.1970270320072...\n",
      "32  2016-07-15  POLYGON ((-75.64898805011781 -14.1988135082976...\n",
      "\n",
      "[2937 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.DataFrame()\n",
    "new_df1 = pd.DataFrame()\n",
    "\n",
    "n = len(polygon)\n",
    "new_df['Date'] = np.resize(list(date.iloc[0]), n)\n",
    "new_df['Polygon'] = polygon\n",
    "\n",
    "for i in range(1, len(date)):\n",
    "    var1 = np.resize(list(date.iloc[i]), n)\n",
    "    new_df1['Date'] = var1\n",
    "    new_df1['Polygon'] = polygon\n",
    "    new_df = new_df.append(new_df1)\n",
    "    \n",
    "print(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                file\n",
      "0   9f0155233f1f9260a6bfbcb1f3cdb830\n",
      "1   cdcb1f4b0b37321293fd68b4656eb565\n",
      "2   981484182e0ebff1a1adb7a4ea947e45\n",
      "3   8c06d111b2062571aa7d97b8536bda89\n",
      "4   6c9098333267d82727e355fbdb6484f0\n",
      "..                               ...\n",
      "84  ba66a3b080c4370efa17e04eb07c6c8d\n",
      "85  fd0cee28789bf90358348060c242ae8c\n",
      "86  e3cb34d5ead6d0d90d353c23d7063cee\n",
      "87  206b0a354debe672dd62b1cf2a4608fc\n",
      "88  49d251a35e4d5181ed61d9afeb3a0045\n",
      "\n",
      "[89 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "paths = sorted(Path(directory).iterdir(), key=os.path.getmtime)\n",
    "paths = list(paths)\n",
    "new_df2 = pd.DataFrame()\n",
    "new_df2['file'] = paths\n",
    "new_df2 = new_df2[:-1]\n",
    "new_df2['file'] = new_df2['file'].apply(str)\n",
    "new_df2['file'] = new_df2['file'].apply(lambda x: x.replace(\"/Users/gbeak/Desktop/Study Materials/img/\", \"\"))\n",
    "\n",
    "\n",
    "print(new_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Polygon</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>POLYGON ((-75.64698264826821 -14.1960684956183...</td>\n",
       "      <td>9f0155233f1f9260a6bfbcb1f3cdb830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>POLYGON ((-75.64964409685477 -14.1970270320072...</td>\n",
       "      <td>cdcb1f4b0b37321293fd68b4656eb565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>POLYGON ((-75.64898805011781 -14.1988135082976...</td>\n",
       "      <td>981484182e0ebff1a1adb7a4ea947e45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>POLYGON ((-75.6396578867764 -14.19970133595172...</td>\n",
       "      <td>8c06d111b2062571aa7d97b8536bda89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>POLYGON ((-75.64231663022875 -14.2006288241436...</td>\n",
       "      <td>6c9098333267d82727e355fbdb6484f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>POLYGON ((-75.64968970670726 -14.1970429501923...</td>\n",
       "      <td>e79de4d20f89fa5e05796330a3dc96ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>POLYGON ((-75.64430202199843 -14.1951328024683...</td>\n",
       "      <td>d1f594ae7816c55e743432563b8c5fea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>POLYGON ((-75.64698264826821 -14.1960684956183...</td>\n",
       "      <td>a4d8eef27c53d1d0bd29d36851b16fd0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>POLYGON ((-75.64964409685477 -14.1970270320072...</td>\n",
       "      <td>0a4c7b0cbf674d27df313200f6e8496b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>POLYGON ((-75.64898805011781 -14.1988135082976...</td>\n",
       "      <td>d69e08745404f0e54b6da943eec16c2a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                            Polygon  \\\n",
       "30  2017-01-01  POLYGON ((-75.64698264826821 -14.1960684956183...   \n",
       "31  2017-01-01  POLYGON ((-75.64964409685477 -14.1970270320072...   \n",
       "32  2017-01-01  POLYGON ((-75.64898805011781 -14.1988135082976...   \n",
       "0   2016-12-22  POLYGON ((-75.6396578867764 -14.19970133595172...   \n",
       "1   2016-12-22  POLYGON ((-75.64231663022875 -14.2006288241436...   \n",
       "..         ...                                                ...   \n",
       "28  2016-07-15  POLYGON ((-75.64968970670726 -14.1970429501923...   \n",
       "29  2016-07-15  POLYGON ((-75.64430202199843 -14.1951328024683...   \n",
       "30  2016-07-15  POLYGON ((-75.64698264826821 -14.1960684956183...   \n",
       "31  2016-07-15  POLYGON ((-75.64964409685477 -14.1970270320072...   \n",
       "32  2016-07-15  POLYGON ((-75.64898805011781 -14.1988135082976...   \n",
       "\n",
       "                                file  \n",
       "30  9f0155233f1f9260a6bfbcb1f3cdb830  \n",
       "31  cdcb1f4b0b37321293fd68b4656eb565  \n",
       "32  981484182e0ebff1a1adb7a4ea947e45  \n",
       "0   8c06d111b2062571aa7d97b8536bda89  \n",
       "1   6c9098333267d82727e355fbdb6484f0  \n",
       "..                               ...  \n",
       "28  e79de4d20f89fa5e05796330a3dc96ea  \n",
       "29  d1f594ae7816c55e743432563b8c5fea  \n",
       "30  a4d8eef27c53d1d0bd29d36851b16fd0  \n",
       "31  0a4c7b0cbf674d27df313200f6e8496b  \n",
       "32  d69e08745404f0e54b6da943eec16c2a  \n",
       "\n",
       "[168 rows x 3 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.concat([new_df, new_df2])\n",
    "new_df['file'] = new_df['file'].shift(-83)\n",
    "new_df = new_df.dropna()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If I had more time ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Solve the loop which creates image files because it was stopped.\n",
    "- Solve the quality of image\n",
    "- Add image file in file column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
